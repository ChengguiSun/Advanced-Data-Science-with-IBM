{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "AIDL_Exercise_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtSLRbb8VCWG",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to install TensorFlow 2.x - as of writing of this notebook, there is only an alpha version available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ5QuSlJVCWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keQe9-gpVCWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9uDvr5bVCWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPmasZwFVCWY",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to create and run a keras model. Since MNIST is getting boring, let's use the fashion MNIST dataset. Fashing MNIST contains 60000 28x28 pixel grey scale images of fashion articles and the corresponding labels between 0-9. It also contains 10000 test images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwK1IUDYVCWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Br_5cNhVCWd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "| Label | Description |\n",
        "| --- | --- |\n",
        "| 0 | T-shirt/top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bczw3nuUVCWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "i = 1120\n",
        "print(train_labels[i])\n",
        "plt.imshow(train_images[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP6kVStSVCWj",
        "colab_type": "text"
      },
      "source": [
        "As expected, we get 60000 images of 28 by 28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnL-cZ6oVCWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7wx6Ng3VCWo",
        "colab_type": "text"
      },
      "source": [
        "The labels are simply a list of 60000 elements, each one is a number (label) between 0 and 9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS7qXdZhVCWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_labels.shape)\n",
        "print(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSBBXDH8VCWs",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look at one image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBhCSG4RVCWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ow8Tbu4VCWz",
        "colab_type": "text"
      },
      "source": [
        "So this is obviously a shoe :) - Let's normalize the data by making sure every pixel value is between 0..1; this is easy in this case:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLKPXsrKVCW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "\n",
        "test_images = test_images / 255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlxtUQgIVCW3",
        "colab_type": "text"
      },
      "source": [
        "In order to write our **hello world** softmax regression model, the following code does the job. If you are familiar with Keras, this is really basic stuff. There is only one catch. The following code doesn't run since the latest stable Keras version is incompatible with the alpha release of TensorFlow 2.0. So the following code is for illustration purposes only. Don't run it, it will destroy your hard drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww_Wd9rbVCW4",
        "colab_type": "text"
      },
      "source": [
        "So from a migration and consistency perspective, it would be nice if we just could change the imports and leave our existing Keras code (which we all love) intact, so let's give it a try:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtF6WUQ4VCW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.nn import relu\n",
        "from tensorflow.nn import softmax\n",
        "\n",
        "\n",
        "    \n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation=relu),\n",
        "    Dense(10, activation=softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=5, verbose=1)\n",
        "\n",
        "#model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0S_C8HyVCW9",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we didn't change the Keras code at all, but now all imports are coming from the tensorflow package. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQNWyTWtVCW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "x_train = train_images\n",
        "x_test = test_images\n",
        "y_train = train_labels\n",
        "y_test = test_labels\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "        #      optimizer=keras.optimizers.Adadelta(),\n",
        "     #         metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}